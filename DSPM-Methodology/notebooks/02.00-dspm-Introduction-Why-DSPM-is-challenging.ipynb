{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9aac1fc-8327-4d1f-a5e9-b27c9e2e123d",
   "metadata": {},
   "source": [
    "<!--BOOK_INFORMATION-->\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figures/DSPM-Book-Cover-Small.png\"><br>\n",
    "\n",
    "This notebook contains an excerpt from the **`Data Science Project Management Methodology - A Guideline for Beginners`** whitepaper written by *Balasubramanian Chandran*; the content is available [on GitHub](https://github.com/BalaChandranGH/Whitepapers/DSPM-Methodology)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a493187b-5ede-485f-8e0c-272a4402e215",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "\n",
    "<[ [The Abstract](01.00-dspm-The-Abstract.ipynb) | [Contents and Acronyms](00.00-dspm-Contents-and-Acronyms.ipynb) | [Summary of existing PM Methodologies](03.00-dspm-Summary-of-existing-PM-Methodologies.ipynb) ]>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b6aeec-5b41-4715-bd8e-5ef6b52e2bed",
   "metadata": {},
   "source": [
    "# 2. Introduction - Why DSPM is challenging?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7343e41c-e0e5-4b40-8d81-780c056fb552",
   "metadata": {},
   "source": [
    "DS projects fail because people overlook the underlying challenges and do not allocate sufficient time to address them. The following are some of the reasons that make the data science projects challenging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991d5c09-959b-419c-926c-9bed76d871c7",
   "metadata": {},
   "source": [
    "## 2.1. Conversion of Business problems into Analytics problems\n",
    "The vague definition of business problems/ requirements by the business is not new. Traditionally, the project teams budget sufficient time in understanding the problem and proceeding with the project development. In the case of DSPM, an additional step of converting the business problem into an analytics problem is required because the problem will be solved by the data; not just by business rules. In other words, the business problems are “qualitative” and the analytics problems are “quantitative” whose solutions can be measured with metrics. \n",
    "\n",
    "This is a make or breaks step in DS projects. If the business problem is not defined analytically right, we will be finding solutions to a wrong problem, and all the project time and efforts will be channelized in the wrong direction! Even if you use the most powerful algorithms, the results will be useless if you are solving the wrong problem. \n",
    "\n",
    "A well-defined analytics problem should be specific, unambiguous, measurable, realistic, and aligned with business goals and should help to find solutions that should predict outcomes or exhibit correlations or categorize/ group or identify patterns/ anomalies or make recommendations. The DS solutions must help the business to make informed decisions backed by data rather than bombarding them with abundant analysis/modeling reports.  \n",
    "\n",
    "_**Example 1:**_\n",
    "\n",
    "``Business problem:``\n",
    "* _How fast the pandemic is spreading across the world?_ \n",
    "\n",
    "``Converted Analytical problem`` (Regression problem – Supervised learning):\n",
    "* _Build a predictive model combining real-time pandemic data collected from across the world, with visualizations on the trend which can be sliced by continent, country, age group, and ethnicity_\n",
    "\n",
    "\n",
    "_**Example 2:**_\n",
    "\n",
    "``Business problem:``\n",
    "* _Develop a system to prevent data theft and sabotage_\n",
    "\n",
    "``Converted Analytical problem`` (Classification problem – Supervised learning):\n",
    "* _Build a predictive model to monitor resources for any suspicious activity, with real-time decision making, visualizations, and alerts_\n",
    "\n",
    "\n",
    "_**Example 3:**_\n",
    "\n",
    "``Business problem:``\n",
    "* _What products can we promote to new customers that they are likely to buy?_\n",
    "\n",
    "``Converted Analytical problem`` (Clustering problem – Unsupervised learning):\n",
    "* _Build an analytical model combining demographic data, age, buying patterns, and report the association of new customers with the clusters of the existing customers_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c972db09-abf3-49a4-9bc3-961984367ee9",
   "metadata": {},
   "source": [
    "## 2.2. Data availability\n",
    "The cases are rare where the required data are readily available to use. The project team needs to spend enough time in collecting the data which may include the identification of:\n",
    "* Sources of data \n",
    "  - Databases, Flat files, Data mining, Web scrapping, Crowd-sourcing, etc.\n",
    "* Types of data \n",
    "  - Structured, Semi-structured, Unstructured (Free-form text, Images, Videos, Audios, etc.)\n",
    "* Volume of data \n",
    "  - Small-size data, Medium-size data, Big data\n",
    "* Cost of data \n",
    "  - Are the data available for free or need to purchase?\n",
    "* Privacy of data\n",
    "  - Knowing the data ownerships and obtaining permissions to use the data (what and what not to) \n",
    "* Right data\n",
    "  - More is not always good: Many a time the project gets lots of data, but most of them are irrelevant and cannot be used\n",
    "  - “It's not who has the best algorithm that wins. It's who has the most data” (Andrew Ng); the “most” means “most relevant and right data”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4601d96e-b1ea-41c6-affe-696f40c6e64c",
   "metadata": {},
   "source": [
    "## 2.3. Data Quality\n",
    "Models learn from data and the quality of the models depends on the quality of the data used to train the models (not to discount the fact that the algorithms also play a crucial role in model outputs). The following are some of the factors that might affect the quality of the data, especially in the case of big data.\n",
    "* Sources of data\n",
    "  - Depending on the business problem, the data sources could be internal or external, or both. We would have better control and understanding of the data if they are generated in-house, and that’s not the case if they are from external-sources\n",
    "  - Inconsistency and incompleteness are inevitable if the data are generated through crowdsourcing such as surveys, public opinions, competitions, contests, etc.\n",
    "* Heterogeneity\n",
    "  - The number of data types or the data variety impose a direct challenge on the understanding and the quality of the data due to the increased complexity\n",
    "  - Consider a case where a project dataset contains data mixed with the following data types,\n",
    "    - Numerical (Integer and Float types)\n",
    "    - Categorical (Nominal, Ordinal, Boolean types)\n",
    "    - Free-form texts, Images, Audios and Videos\n",
    "    - Real-time streaming data <br>\n",
    "      The quality may be compromised with the increased complexity.\n",
    "  - To reduce the complexity and to improve the quality, it’s important to maintain the metadata (information about the data, a.k.a. data description)\n",
    "  - Generating metadata itself may be challenging; should they be automated or manual?\n",
    "  - Metadata generation could be a time-consuming task as well\n",
    "* Volume\n",
    "  - Working with 100s or 1000s of samples and 10s of attributes is much easier than working with 10s of 1000s of attributes and millions of samples which usually suffer from quality\n",
    "* Messy data\n",
    "  - Most of the time the project team gets inaccurate, inconsistent & incomplete data to work with\n",
    "* Lack of Skills\n",
    "  - In the data science world, people say “finding a true Data scientist is like finding a unicorn” especially in one member team where one person plays all the roles in a data science project such as data and analytics manager, data scientist, business analyst, data analyst, data engineer, data architect, ML engineer, statistician, etc.\n",
    "  - Lack of talents in terms of domain expertise and technical expertise in-house\n",
    "* Reliability \n",
    "  - Big data are often messy, complex, and untrustworthy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dbc5a5-c9a9-49aa-9ece-7fe58ad0b329",
   "metadata": {},
   "source": [
    "## 2.4. Data Pre-processing\n",
    "This is the most time-consuming step in a data science project. The collected data may not be (in most cases “will not be”) in the form that they can be used as they are. They need to be processed and brought into a form that the model can analyze and produce the results. Data Pre-processing is also called Data Preparation or Data Wrangling or Data Augmentation. Some of the activities involved in this step are,\n",
    "* Data cleaning\n",
    "  - Removal of duplicates (samples/ features), handling outliers, handling missing values, handling inconsistent/ errors in data, etc.\n",
    "* Feature selection\n",
    "  - Dimensionality Reduction (e.g., PCA)\n",
    "* Feature engineering\n",
    "  - Combining existing features to create a new one (e.g., total), deriving a new feature from the existing ones (e.g., mean), data formatting/ reformatting, etc.\n",
    "* Split datasets into Train and Test datasets\n",
    "* Data transforms\n",
    "  - Numerical type - Standardization, Normalization, etc.\n",
    "  - Categorical type - One-Hot encode, Dummy encode, etc.\n",
    "* Handling imbalanced classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49e46bd-60fc-43c2-8f28-98cdb3723eff",
   "metadata": {},
   "source": [
    "## 2.5. Research and Experimentation\n",
    "All DS projects do not demand the use of ML. However, most of the DS projects these days use ML to handle a high volume of data and a high number of dependent attributes to generate the outputs. Depending on the size, complexity, and use of ML, the data science projects involve a certain amount of research, ranging from simple (e.g., algorithm selection) to advanced (e.g., new algorithm development). One of the common mistakes by the novices is “discounting the human factor in deciding on the final solution”.\n",
    "* Depending on the algorithms to finalize the solution is not a good option\n",
    "* Data scientists should have a deeper knowledge of the error analysis and model parameter tuning to improve the model performances before selecting the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2879cd41-c76e-417a-afb2-8bd7cae1afb8",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "<br>\n",
    "\n",
    "<[ [The Abstract](01.00-dspm-The-Abstract.ipynb) | [Contents and Acronyms](00.00-dspm-Contents-and-Acronyms.ipynb) | [Summary of existing PM Methodologies](03.00-dspm-Summary-of-existing-PM-Methodologies.ipynb) ]>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

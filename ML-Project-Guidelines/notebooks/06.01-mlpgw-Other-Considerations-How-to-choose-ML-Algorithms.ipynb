{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f36f4fcb-9542-4ae6-9419-5afd2aae21d8",
   "metadata": {},
   "source": [
    "<!--BOOK_INFORMATION-->\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figures/MLPG-Book-Cover-Small.png\"><br>\n",
    "\n",
    "This notebook contains an excerpt from the **`Machine Learning Project Guidelines - For Beginners`** whitepaper written by *Balasubramanian Chandran*; the content is available [on GitHub](https://github.com/BalaChandranGH/Whitepapers/ML-Project-Guidelines)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9b6351-c01f-4f7e-86c1-2e3a069e4027",
   "metadata": {},
   "source": [
    "<br>\n",
    "<!--NAVIGATION-->\n",
    "\n",
    "<[ [ML Project - Stages in detail with Guidelines](05.00-mlpgw-ML-Project-Stages-in-detail-with-Guidelines.ipynb) | [Contents and Acronyms](00.00-mlpgw-Contents-and-Acronyms.ipynb) | [Other Considerations - Metrics-and-Error-Analysis](06.02-mlpgw-Other-Considerations-Metrics-and-Error-Analysis.ipynb) ]>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a886a76e-b7ed-4251-be90-60715813d045",
   "metadata": {},
   "source": [
    "# 6. Other Considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20213464-1afd-4bbc-89e2-42005a85b6be",
   "metadata": {},
   "source": [
    "## 6.1. How to choose ML Algorithms?\n",
    "* No free lunch theorem:\n",
    "  - “All algorithms perform equally well when their performances are averaged over all possible objective functions”\n",
    "  - There is no single best algorithm for predictive modeling problems such as regression and classification\n",
    "* Determining which algorithm to use depends on many factors from the ``type of problem`` at hand to the ``type of output`` we are looking for\n",
    "* The algorithm selection depends on the following factors, to name a few:\n",
    "  1. Business objective or Problem statement (both in business terms and analytical terms)\n",
    "  2. Type of the data\n",
    "  3. Size of the data\n",
    "  4. Feature space (number of features)\n",
    "  5. Linearity \n",
    "  6. Accuracy and/or Interpretability of the output\n",
    "  7. Algorithm run-time or Training time\n",
    "  8. Available computing power"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c17b574-e5ae-47cb-8d39-816b9ca7c4a4",
   "metadata": {},
   "source": [
    "### 6.1.1. Defining Business objective / Problem statement\n",
    "* Define the problem statement both in business terms and analytical terms\n",
    "* Use the following guideline to select the algorithms:\n",
    "  - ``Predict numerical values`` such as forecast: ``REGRESSION`` problem\n",
    "    - Linear – Low computing power, Fast training time<br>\n",
    "      _LinearRegression, LASSO, Ridge, ElasticNet_\n",
    "    - Non-linear – High computing power, Long training time, More memory<br>\n",
    "      _KNN, SVM, Decision Trees, Neural Networks_\n",
    "    - Ensembles (Bagging & Boosting) – Accurate, Fast training time, More memory <br>\n",
    "      _Random Forest, Extreme Boosting_\n",
    "  - ``Predict categories/classes`` (both binary class & multi-class): ``CLASSIFICATION`` problem\n",
    "    - Logistic Regression – Fast training time\n",
    "    - Neural Network – Accurate, Long training time\n",
    "    - Random Forest – Accurate, Fast training time, More memory\n",
    "    - SVM – Long training time, More memory, use under 100 features\n",
    "  - ``Discover structure``: ``CLUSTERING`` problem\n",
    "    - K-Means\n",
    "  - ``Find unusual occurrences``: ``Anomaly Detection``\n",
    "    - One-class SVM – use under 100 features\n",
    "    - Local Outlier Factor (neighbors-based technique)\n",
    "    - Minimum Covariance Determinant \n",
    "    - Isolation Forest (ensemble technique)\n",
    "  - ``Generate Recommendations``: ``Recommender System``\n",
    "    - Content-based filtering (Supervised learning - Classification):\n",
    "       - Recommends products that are similar to the ones that a user has liked in the past\n",
    "    - Collaborative Filtering (Supervised learning - Classification):\n",
    "       - Recommends products based on the user behavior that is similar to other user groups\n",
    "       - Simple and appropriate for small datasets\n",
    "    - Clustering (Unsupervised Learning):\n",
    "       - Appropriate for large datasets\n",
    "    - Neural Networks\n",
    "       - Deep learning approach used by YouTube\n",
    "  - ``Information Extraction``: ``Natural Language Processing (NLP)``\n",
    "    - NLTK (Natural Language Toolkit)\n",
    "  - ``Networks and Graphs analysis``:\n",
    "    - NetworkX\n",
    "  - ``Geographic/Geospatial/Maps``:\n",
    "    - Folium\n",
    "  - ``Image and video processing``:\n",
    "    - OpenCV\n",
    "    - TensorFlow (deep learning platform)\n",
    "    - Keras (Python API built on top of TensorFlow)\n",
    "    - PyTorch (deep learning library)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fc88e0-6ac3-4f8a-b547-0a12974b660a",
   "metadata": {},
   "source": [
    "### 6.1.2. Type of data\n",
    "* Datasets may contain only numerical values or categorical values or texts or images or audios or videos or a mixture of any/all of these\n",
    "* The type(s) of the data play an important role in branching out the options for algorithm types such as Regression, Classification, Clustering, Text extraction, Maps, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c0b66b-2a98-4027-aecb-1d66eefb52ed",
   "metadata": {},
   "source": [
    "### 6.1.3. Size of the data\n",
    "* It’s recommended to gather a good amount of data to get reliable predictions, however, many a time, the availability of data is a constraint\n",
    "* ``If the training data is smaller`` or it has a fewer # of observations and a higher # of features, then ``choose algorithms with high bias/low variance like Linear regression, Naïve Bayes, or Linear SVM``\n",
    "* ``If the training data is sufficiently large`` and the # of observations is higher as compared to the # of features, then, ``choose low bias/high variance algorithms like KNN, Decision trees, or kernel SVM``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6826fbb2-4921-431f-aa87-50e42c2f04da",
   "metadata": {},
   "source": [
    "### 6.1.4. Feature space (number of features)\n",
    "* The dataset may have a large number of features that may not all be relevant and significant\n",
    "* For a certain type of data, such as genetics or textual, the number of features can be very large compared to the number of data points\n",
    "* A large number of features can bog down some algorithms, making training time unfeasibly long\n",
    "* ``If the feature space is large and lesser observations``, then ``use Linear SVM``\n",
    "* Use PCA and feature selection techniques to reduce dimensionality and select important features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad468b4b-f347-4494-82d0-e325c9c3d30c",
   "metadata": {},
   "source": [
    "### 6.1.5. Linearity\n",
    "* Many algorithms work on the assumption that classes can be separated by a straight line, e.g., Logistic Regression and SVMs\n",
    "* Linear Regression algorithms assume that data trends follow a straight line, If the data is linear, then these algorithms perform quite good\n",
    "* However, not always is the data is linear, so we require other algorithms which can handle high dimensional and complex data structures, e.g., kernel SVM, Random Forest, NNs\n",
    "* ``The best way to find out the linearity is to either fit a linear line or run a Logistic Regression or Linear SVM and check for residual errors. A higher error means the data is not linear and would need complex algorithms to fit``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72eab7d-418a-4eef-84e7-9f53080e2ece",
   "metadata": {},
   "source": [
    "### 6.1.6. Accuracy/Interpretability of the output\n",
    "* ``Accuracy``: A function that predicts a response value for a given observation, which is close to the true response value for that observation\n",
    "* ``Flexible models`` give ``high accuracy`` but ``low interpretability`` (e.g., KNN with k=1)\n",
    "* ``Restrictive models`` give ``low accuracy`` but ``high interpretability`` (e.g., linear regression)\n",
    "* The choice of the algorithm depends on the objective of the business problem\n",
    "* If the ``inference is the goal``, then ``Restrictive models are better`` as they are much more interpretable\n",
    "* ``If accuracy is the goal``, then ``Flexible models are better``\n",
    "* In general, as the flexibility of a method increases, its interpretability decreases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654e13db-35c5-4313-8f03-7062c1c194a2",
   "metadata": {},
   "source": [
    "**Trade-off between _``Accuracy``_ and _``Interpretability``_**<br>\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figures/MLPG-OC-AccuracyVsInterpretability.png\"><br>\n",
    "<br><br><br><br><br>\n",
    "Image credit [(Source)](https://cdn.oreillystatic.com/en/assets/1/event/105/Overcoming%20the%20Barriers%20to%20Production-Ready%20Machine-Learning%20Workflows%20Presentation%201.pdf)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b997f2-f01f-4f03-a370-b59335c309ba",
   "metadata": {},
   "source": [
    "<br>**Trade-off between _``Flexibility``_ and _``Interpretability``_**<br>\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figures/MLPG-OC-FlexibilityVsInterpretability.png\"><br>\n",
    "<br><br><br><br><br>\n",
    "Image credit [(Source)](https://faculty.marshall.usc.edu/gareth-james/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee55183-7226-4387-bd45-0f46640ce675",
   "metadata": {},
   "source": [
    "### 6.1.7. Algorithm run-time/Training time\n",
    "* Higher accuracy typically means higher training time\n",
    "* Also, algorithms require more time to train on large training data\n",
    "* In real-world applications, the choice of algorithm is driven by these two factors predominantly\n",
    "* ``Short run-time and easy to implement but low accuracy: Naïve Bayes and Linear and Logistic regression``\n",
    "* ``Long run-time and not so easy to implement but high accuracy: Random Forest, NN, SVM``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c245be-218b-4c17-8411-1d78c5d0af1a",
   "metadata": {},
   "source": [
    "### 6.1.8. Available computing power\n",
    "* The choice of algorithms is based on the available CPUs and GPUs as well\n",
    "* If multiple CPUs and GPUs are available with multiple cores, then deep learning can be a good option"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fed15f-bf4d-4eb2-96f2-3d7f5b484af6",
   "metadata": {},
   "source": [
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figures/MLPG-OC-MLAlgorithmsCheatSheet1.png\"><br>\n",
    "<br><br><br><br><br><br><br><br>\n",
    "Image credit [(Source)](https://blogs.sas.com/content/subconsciousmusings/2020/12/09/machine-learning-algorithm-use/)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d20ee1-4a4f-4176-b3dc-cca9d613a5c3",
   "metadata": {},
   "source": [
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figures/MLPG-OC-MLAlgorithmsCheatSheet2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d888026-0fdc-4603-9428-a72f4500c160",
   "metadata": {},
   "source": [
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figures/MLPG-OC-MLAlgorithmsCheatSheet3.png\"><br>\n",
    "Image credit [(Source)](https://www.kdnuggets.com/2020/05/guide-choose-right-machine-learning-algorithm.html)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f98561-7b09-4f47-b2b7-ee40f81654eb",
   "metadata": {},
   "source": [
    "### 6.1.9. Rule of Thumb\n",
    "* **``It's not who has the best algorithm that wins. It's who has the most data``** – (Andrew Ng)\n",
    "* **``An inferior algorithm with enough data can outperform a superior algorithm with less data``** – (A. Ng)\n",
    "* **``More data beats better algorithms but better data beats more data``** – (Bala)<br>\n",
    "  **Step1**: Define the problem in analytical terms from the business objectives<br>\n",
    "  **Step2**: Start with a simple algorithm, build a baseline model, benchmark it, and be familiar with the data<br>\n",
    "  **Step3**: Then try with more complex algorithms and build complex models to meet the business needs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d47a88-0396-44c5-bbfe-21157a8224ac",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "<br>\n",
    "\n",
    "<[ [ML Project - Stages in detail with Guidelines](05.00-mlpgw-ML-Project-Stages-in-detail-with-Guidelines.ipynb) | [Contents and Acronyms](00.00-mlpgw-Contents-and-Acronyms.ipynb) | [Other Considerations - Metrics-and-Error-Analysis](06.02-mlpgw-Other-Considerations-Metrics-and-Error-Analysis.ipynb) ]>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

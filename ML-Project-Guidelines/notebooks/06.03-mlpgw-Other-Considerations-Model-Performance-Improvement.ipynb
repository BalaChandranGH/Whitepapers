{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f36f4fcb-9542-4ae6-9419-5afd2aae21d8",
   "metadata": {},
   "source": [
    "<!--BOOK_INFORMATION-->\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figures/MLPG-Book-Cover-Small.png\"><br>\n",
    "\n",
    "This notebook contains an excerpt from the **`Machine Learning Project Guidelines - For Beginners`** whitepaper written by *Balasubramanian Chandran*; the content is available [on GitHub](https://github.com/BalaChandranGH/Whitepapers/ML-Project-Guidelines)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9b6351-c01f-4f7e-86c1-2e3a069e4027",
   "metadata": {},
   "source": [
    "<br>\n",
    "<!--NAVIGATION-->\n",
    "\n",
    "<[ [Other Considerations - Metrics-and-Error-Analysis](06.02-mlpgw-Other-Considerations-Metrics-and-Error-Analysis.ipynb) | [Contents and Acronyms](00.00-mlpgw-Contents-and-Acronyms.ipynb) | [Summary](07.00-mlpgw-Summary.ipynb) ]>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe5d33a-4d7b-40c4-acd9-ed37534f2f15",
   "metadata": {},
   "source": [
    "# 6. Other Considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7840258e-0f9b-4364-89f4-c64b325cd51a",
   "metadata": {},
   "source": [
    "##  6.3. Model Performance Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a886a76e-b7ed-4251-be90-60715813d045",
   "metadata": {},
   "source": [
    "### 6.3.1. L1 and L2 regularization\n",
    "* One of the most common problems for data science professionals is **overfitting**, i.e., the model performing well on the train dataset and performing poorly on the test dataset\n",
    "* Regularization is a technique that makes slight modifications to the learning algorithm such that the model generalizes better and it improves the model’s performance on the unseen data as well\n",
    "* In ML the Regularization penalizes the coefficients and in deep learning, it penalizes the weight matrices of the nodes which will result in a simpler model and slight underfitting of the train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2528e7f9-5523-429a-9ee7-35c28c7999b3",
   "metadata": {},
   "source": [
    "![](figures/MLPG-OC-UFJROFCurves.png) ![](figures/MLPG-OC-TrainingVsTestSetErrors.png)<br>\n",
    "When the complexity of the model increases the training error reduces but the testing error doesn’t."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526c4745-831b-4d85-9c49-4d01bd19d4b4",
   "metadata": {},
   "source": [
    "**Regularization techniques:**\n",
    "* There are **5 types**:\n",
    "```\n",
    "  1) L1 Regularization (LASSO)        - used in both ML and DL \n",
    "  2) L2 Regularization (Ridge)        - used in both ML and DL\n",
    "  3) Dropout                          - used in DL\n",
    "  4) Data Augmentation/transformation - used in DL\n",
    "  5) Early stopping                   - used in DL\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ddabdb-a41f-4f7b-8715-47d28a2b3740",
   "metadata": {},
   "source": [
    "* **L1 Regularization (LASSO):**\n",
    "  - A most common type of regularization\n",
    "  - Updates the general cost function by adding a ``regularization term``\n",
    "  - ``L1 gives output in binary weights from 0 to 1`` for the model's features and is adopted for decreasing the number of features in a high dimensional dataset, which in turn reduces the complexity of the model (i.e., reduces the overfitting by generalizing the model better)\n",
    "  - ``L1 tends to shrink coefficients to zero``\n",
    "  - L1 is useful for feature selection, as we can drop any variables with coefficients that go to zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3980049-8561-48a0-a22d-39f71d3dd34c",
   "metadata": {},
   "source": [
    "* **L2 Regularization (Ridge):**\n",
    "  - A most common type of regularization\n",
    "  - Updates the general cost function by adding a ``regularization term``\n",
    "  - L2 regularization is also known as _``weight decay``_ as it forces the weights to ``decay towards zero (but not exactly zero)``\n",
    "  - L2 tends to shrink coefficients evenly\n",
    "  - L2 is useful when we have collinear/codependent features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d17c8b3-05cc-481b-9ee9-7ca2f57c3641",
   "metadata": {},
   "source": [
    "* **Dropout:**\n",
    "  - A most frequently used regularization technique in DL (Artificial Neural Networks)\n",
    "  - At every iteration, it randomly selects some nodes and removes them along with all of their incoming and outgoing connections, so each iteration has a different set of nodes, and this results in a different set of outputs\n",
    "  - It can also be thought of as an ensemble technique in machine learning\n",
    "  - Ensemble models usually perform better than a single model as they capture more randomness, similarly, dropout also performs better than a normal neural network model\n",
    "  - Dropout is usually preferred when we have a large NN structure to introduce more randomness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71890da1-2d81-4112-8466-d0676b75982c",
   "metadata": {},
   "source": [
    "* **Data Augmentation:**\n",
    "  - The simplest way to reduce overfitting is to increase the size of the training data thru data transformations such as rotating, flipping, scaling, etc., if we are dealing with images in the datasets\n",
    "  - It may be too costly in ML, but may not be costly in DL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6666f9b0-6f2c-4baf-9843-2bfc11fafe15",
   "metadata": {},
   "source": [
    "* **Early stopping:**\n",
    "  - A kind of cross-validation strategy where we keep one part of the training set as the validation set\n",
    "  - When we see that the performance on the validation set is getting worse, we immediately stop the training on the model\n",
    "![](figures/MLPG-OC-EarlyStopping.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb84a4c-c84c-4855-babc-d0f1418fb5a0",
   "metadata": {},
   "source": [
    "### 6.3.2. Overfitting, Underfitting, and how to limit Overfitting\n",
    "**Generalization:**\n",
    "* It refers to how well the concepts learned by an ML model are applied to new data, i.e., to specific examples not seen by the model when it was learning\n",
    "* The goal of an ML model is to generalize well from the training data to any data from a problem domain\n",
    "* \tOverfitting and underfitting are the two biggest causes for the poor performance of ML algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dffcf1-daa8-45c6-9c9a-cc03d9d60ddc",
   "metadata": {},
   "source": [
    "**Overfitting:**\n",
    "* A model that performs good on the training data and poorly generalizes other data\n",
    "* It happens when a model learns the details and noises in the training data to the extent that it negatively impacts the performance of the model on new data. This means that the noise or random fluctuations in the training data is picked up and learned as concepts by the model. The problem is that these concepts do not apply to new data and negatively impact the model's ability to generalize\n",
    "* Overfitting is more likely with nonparametric and nonlinear models that have more flexibility when learning a target function. For example, decision trees are a nonparametric ML algorithm that is very flexible and is subject to overfitting training data ``(This problem can be addressed by pruning a tree after it has learned to remove some of the detail it has picked up.)``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8346285b-026e-4479-833a-b413f101d6e2",
   "metadata": {},
   "source": [
    "**Underfitting:**\n",
    "* A model that performs poorly on the training data and poorly generalizes other data\n",
    "* It refers to a model that can neither model the training data well nor generalizes to new data\n",
    "* An underfit ML model is not a suitable model and will be ``obvious`` as it will have poor performance on the training data\n",
    "* Underfitting is often not discussed as it is easy to detect given a good performance metric. The remedy is to move on and try alternate ML algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a82ff4-26a5-4965-9594-11e67c0fc110",
   "metadata": {},
   "source": [
    "**Good-fit (or) Right-fit:**\n",
    "* Ideally, we want to select a model at the sweet spot between underfitting and overfitting\n",
    "* This is the goal but is very difficult to do in practice\n",
    "* To understand this goal, we can look at the performance of an ML algorithm over time as it is learning training data, then, plot both the skill on the training data and the skill on a test dataset\n",
    "* Over time, as the algorithm learns, the error for the model on the training data goes down and so does the error on the test dataset\n",
    "* If we train for too long, the performance on the training dataset may continue to decrease because the model is overfitting and learning the irrelevant detail and noise in the training dataset, at the same time, the error for the test set starts to rise again as the model’s ability to generalize decreases\n",
    "* The sweet spot is the point just before the error on the test dataset starts to increase where the model has good skill on both the training dataset and the unseen test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f11106-f372-4001-b844-18e7fb5874ac",
   "metadata": {},
   "source": [
    "**How to limit overfitting:**\n",
    "* Both overfitting and underfitting can lead to poor model performance\n",
    "* Overfitting occurs when there are outliers, noises, random fluctuations, skews, etc. in the dataset\n",
    "* There are 2 main options to address the issue of overfitting:\n",
    "  - Data pre-processing\n",
    "    - Data cleaning steps help to remove noises, outliers, noises, random fluctuations, etc.\n",
    "    - Feature selection and feature engineering steps help to retain only the most relevant features\n",
    "    - Data transformation steps help to remove skews\n",
    "  - Regularization \n",
    "    - Keeps all the features, but reduces the magnitude of the parameters\n",
    "    - Works well when we have a lot of slightly useful features\n",
    "* There are 2 important techniques that we can use when evaluating ML algorithms to limit overfitting:\n",
    "  - Use a resampling technique to estimate model accuracy (``k-fold cross-validation``)\n",
    "    - The most popular resampling technique is k-fold cross-validation which allows us to train and test our model k-times on different subsets of training data and build up an estimate of the performance of an ML model on unseen data\n",
    "  - Hold back a validation dataset (``validation dataset; not to be confused with test dataset``)\n",
    "    - A validation dataset is simply a subset of our training data that we hold back from our ML algorithms until the very end of your project\n",
    "    - After we have selected and tuned our ML algorithms on our training dataset we can evaluate the learned models on the validation dataset to get a final objective idea of how the models might perform on unseen data\n",
    "* Using cross-validation is a gold standard in applied ML for estimating model accuracy on unseen data\n",
    "* If we have the data, using a validation dataset is also an excellent practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac37c7df-091e-48a9-a32c-829cc47d1c33",
   "metadata": {},
   "source": [
    "### 6.3.3. Data leakage: How to detect and prevent it?\n",
    "**Data leakage:**\n",
    "* When the data we are using to train contains information about what we are trying to predict\n",
    "* Introducing information about the target during training that would not be available during actual use\n",
    "* ``Examples:``\n",
    "  - _``Including test data along with the training data``_\n",
    "  - _``Including the label to be predicted as a feature``_\n",
    "* If the model performance is too good to be true, it is likely due to \"giveaway\" features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3a5f32-14fa-4325-bc98-304e839eeb35",
   "metadata": {},
   "source": [
    "**Examples of Data leakages:**\n",
    "* ``Leakage in training data:``\n",
    "  - Performing data preprocessing using parameters or results from analyzing the entire dataset: Normalizing and rescaling, detecting and removing outliers, estimating missing values, feature selection, etc.\n",
    "  - Time-series datasets: Using records from the future when computing features from the current prediction\n",
    "  - Errors in data values/gathering or missing variable indicators (e.g., the special value 999) can encode information about missing data that reveals information about the future\n",
    "* ``Leakage in features:``\n",
    "  - Removing variables that are not legitimate without also removing variables that encode the same or related information (e.g., diagnosis info may still exist in a patient ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03378a63-51e5-4155-913e-30f1cc3ccb2e",
   "metadata": {},
   "source": [
    "**Detecting Data leakage:**\n",
    "* Before building the model:\n",
    "  - Perform exploratory data analysis (EDA) to find surprises in the data\n",
    "  - Are there features very highly correlated with the target value?\n",
    "* After building the model:\n",
    "  - Look for surprising feature behavior in the fitted/trained model\n",
    "  - Are there features with very high weights, or high information gain?\n",
    "  - Simple rule-based models like DTs can help with features like account numbers, patient IDs\n",
    "  - Is overall model performance surprisingly good compared to known results on the same dataset, or for similar problems on similar datasets?\n",
    "* After real-world deployment of the trained model:\n",
    "  - Is the trained model generalizing well to new data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056e96b9-1948-47ef-b532-89aee365f26b",
   "metadata": {},
   "source": [
    "**Preventing/minimizing Data leakage:**\n",
    "* Perform data preparation within the train and test datasets separately (not using the entire dataset):\n",
    "  - Perform feature selection, transform/scale/normalize data, etc. for train & test datasets separately\n",
    "  - Care must be taken while “handling the missing numerical values – especially when replacing with a test statistic such as mean/median/mode/forward-fill/back-fill)”. For example, if we use ``mean``, \n",
    "    - We should compute the ``mean`` value on the training set and use it to fill the missing values in the training set\n",
    "    - Save the mean value that we have computed\n",
    "    - Later, replace missing values in the test set with the ``mean`` value to evaluate the system\n",
    "  - The parameters used to prepare the test dataset MUST be the same as the ones used in the training dataset\n",
    "* Perform data preparation within each cross-validation fold separately (not using the training dataset):\n",
    "  - Transform/scale/normalize data, etc. within each fold of the CV dataset separately\n",
    "  - The parameters used to prepare each CV fold MUST be the same as the ones used in the training dataset\n",
    "* With time-series data, use timestamp cutoff:\n",
    "  - The cutoff value is set to the specific time point where prediction is to occur using current and previous/old records\n",
    "  - Using a cutoff time will make sure you aren't accessing any data records that were gathered after the prediction time, i.e., in the future\n",
    "* Before any work with a new dataset, split off a final test validation dataset\n",
    "  - ... if you have enough data\n",
    "  - Use this final test dataset as the very last step in your validation\n",
    "  - Helps to check the true generalization performance of any trained models\n",
    "* In a nutshell:\n",
    "  - Apply any feature scaling or transformation technique (such as normalization or standardization etc.) on training & testing datasets separately to prevent DATA LEAKAGE. In other words, _``DO NOT apply`` **``data transformation techniques``** ``before splitting the datasets into training & testing datasets``_\n",
    "  - Apply any algorithm fine-tuning of hyperparameter technique on training & testing datasets separately to prevent DATA LEAKAGE. In other words, _``DO NOT apply`` **``algorithm fine-tuning techniques``** ``before splitting the datasets into training & testing datasets``_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d47a88-0396-44c5-bbfe-21157a8224ac",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "<br>\n",
    "\n",
    "<[ [Other Considerations - Metrics-and-Error-Analysis](06.02-mlpgw-Other-Considerations-Metrics-and-Error-Analysis.ipynb) | [Contents and Acronyms](00.00-mlpgw-Contents-and-Acronyms.ipynb) | [Summary](07.00-mlpgw-Summary.ipynb) ]>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
